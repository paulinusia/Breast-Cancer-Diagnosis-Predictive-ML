From most significant classifier to least
Classifier w/ optimal hyperameters: 
LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
Confusion matrix
              precision    recall  f1-score   support

           0       0.93      0.99      0.96       108
           1       0.99      0.93      0.96       107

    accuracy                           0.96       215
   macro avg       0.96      0.96      0.96       215
weighted avg       0.96      0.96      0.96       215

Area under Precision and Recall Curve: 0.9762214735926973
F1s score: 0.9565217391304348
Accuracy: 0.958139534883721

Classifier w/ optimal hyperameters: 
KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,
                     weights='uniform')
Confusion matrix
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       108
           1       0.97      0.95      0.96       107

    accuracy                           0.96       215
   macro avg       0.96      0.96      0.96       215
weighted avg       0.96      0.96      0.96       215

Area under Precision and Recall Curve: 0.9739777067097215
F1s score: 0.9622641509433962
Accuracy: 0.9627906976744186

Classifier w/ optimal hyperameters: 
SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',
    kernel='linear', max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
Confusion matrix
              precision    recall  f1-score   support

           0       0.94      0.98      0.96       108
           1       0.98      0.93      0.96       107

    accuracy                           0.96       215
   macro avg       0.96      0.96      0.96       215
weighted avg       0.96      0.96      0.96       215

Area under Precision and Recall Curve: 0.9737648678249827
F1s score: 0.9569377990430622
Accuracy: 0.958139534883721

Classifier w/ optimal hyperameters: 
DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=7,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=0, splitter='best')
Confusion matrix
              precision    recall  f1-score   support

           0       0.94      0.95      0.95       108
           1       0.95      0.94      0.95       107

    accuracy                           0.95       215
   macro avg       0.95      0.95      0.95       215
weighted avg       0.95      0.95      0.95       215

Area under Precision and Recall Curve: 0.9623311995341455
F1s score: 0.948356807511737
Accuracy: 0.9488372093023256

Classifier w/ optimal hyperameters: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=100, n_iter_no_change=5, n_jobs=None, penalty='l1',
              power_t=0.5, random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
Confusion matrix
              precision    recall  f1-score   support

           0       0.85      0.97      0.91       108
           1       0.97      0.83      0.89       107

    accuracy                           0.90       215
   macro avg       0.91      0.90      0.90       215
weighted avg       0.91      0.90      0.90       215

Area under Precision and Recall Curve: 0.9414439677574818
F1s score: 0.8944723618090453
Accuracy: 0.9023255813953488

Classifier w/ optimal hyperameters: 
Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,
           fit_intercept=True, max_iter=10, n_iter_no_change=5, n_jobs=None,
           penalty=None, random_state=0, shuffle=True, tol=0.001,
           validation_fraction=0.1, verbose=0, warm_start=False)
Confusion matrix
              precision    recall  f1-score   support

           0       0.92      0.84      0.88       108
           1       0.85      0.93      0.89       107

    accuracy                           0.88       215
   macro avg       0.89      0.88      0.88       215
weighted avg       0.89      0.88      0.88       215

Area under Precision and Recall Curve: 0.9079456115237318
F1s score: 0.8878923766816144
Accuracy: 0.8837209302325582

Classifier w/ optimal hyperameters: 
MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
              beta_2=0.999, early_stopping=False, epsilon=1e-08,
              hidden_layer_sizes=(5, 2), learning_rate='constant',
              learning_rate_init=0.001, max_iter=25, momentum=0.9,
              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
              random_state=None, shuffle=True, solver='adam', tol=0.0001,
              validation_fraction=0.1, verbose=False, warm_start=False)
Confusion matrix
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       108
           1       0.50      1.00      0.66       107

    accuracy                           0.50       215
   macro avg       0.25      0.50      0.33       215
weighted avg       0.25      0.50      0.33       215

Area under Precision and Recall Curve: 0.7488372093023256
F1s score: 0.6645962732919255
Accuracy: 0.49767441860465117

