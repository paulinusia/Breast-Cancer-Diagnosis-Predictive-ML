From most significant classifier to least
Classifier w/ optimal hyperameters: 
KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,
                     weights='uniform')
Confusion matrix
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       108
           1       0.97      0.94      0.95        63

    accuracy                           0.96       171
   macro avg       0.97      0.96      0.96       171
weighted avg       0.96      0.96      0.96       171

Area under Precision and Recall Curve: 0.963556432063766
F1s score: 0.9516129032258064
Accuracy: 0.9649122807017544

Classifier w/ optimal hyperameters: 
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
Confusion matrix
              precision    recall  f1-score   support

           0       0.99      0.94      0.96       108
           1       0.90      0.98      0.94        63

    accuracy                           0.95       171
   macro avg       0.94      0.96      0.95       171
weighted avg       0.96      0.95      0.95       171

Area under Precision and Recall Curve: 0.9442628309905198
F1s score: 0.9393939393939393
Accuracy: 0.9532163742690059

Classifier w/ optimal hyperameters: 
DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=7,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=0, splitter='best')
Confusion matrix
              precision    recall  f1-score   support

           0       0.98      0.94      0.96       108
           1       0.90      0.97      0.93        63

    accuracy                           0.95       171
   macro avg       0.94      0.95      0.94       171
weighted avg       0.95      0.95      0.95       171

Area under Precision and Recall Curve: 0.9385043491080642
F1s score: 0.9312977099236641
Accuracy: 0.9473684210526315

Classifier w/ optimal hyperameters: 
SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',
    kernel='linear', max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
Confusion matrix
              precision    recall  f1-score   support

           0       0.98      0.93      0.95       108
           1       0.88      0.97      0.92        63

    accuracy                           0.94       171
   macro avg       0.93      0.95      0.94       171
weighted avg       0.94      0.94      0.94       171

Area under Precision and Recall Curve: 0.9320039228506047
F1s score: 0.9242424242424243
Accuracy: 0.9415204678362573

Classifier w/ optimal hyperameters: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=10,
              n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,
              random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
Confusion matrix
              precision    recall  f1-score   support

           0       0.95      0.78      0.86       108
           1       0.71      0.94      0.81        63

    accuracy                           0.84       171
   macro avg       0.83      0.86      0.83       171
weighted avg       0.86      0.84      0.84       171

Area under Precision and Recall Curve: 0.8353715614337047
F1s score: 0.8082191780821918
Accuracy: 0.8362573099415205

Classifier w/ optimal hyperameters: 
Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,
           fit_intercept=True, max_iter=10, n_iter_no_change=5, n_jobs=None,
           penalty=None, random_state=0, shuffle=True, tol=0.001,
           validation_fraction=0.1, verbose=0, warm_start=False)
Confusion matrix
              precision    recall  f1-score   support

           0       1.00      0.22      0.36       108
           1       0.43      1.00      0.60        63

    accuracy                           0.51       171
   macro avg       0.71      0.61      0.48       171
weighted avg       0.79      0.51      0.45       171

Area under Precision and Recall Curve: 0.7142857142857143
F1s score: 0.6
Accuracy: 0.5087719298245614

Classifier w/ optimal hyperameters: 
MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
              beta_2=0.999, early_stopping=False, epsilon=1e-08,
              hidden_layer_sizes=(100, 3), learning_rate='constant',
              learning_rate_init=0.001, max_iter=100, momentum=0.9,
              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
              random_state=None, shuffle=True, solver='adam', tol=0.0001,
              validation_fraction=0.1, verbose=False, warm_start=False)
Confusion matrix
              precision    recall  f1-score   support

           0       0.63      1.00      0.77       108
           1       0.00      0.00      0.00        63

    accuracy                           0.63       171
   macro avg       0.32      0.50      0.39       171
weighted avg       0.40      0.63      0.49       171

Area under Precision and Recall Curve: 0.6842105263157895
F1s score: 0.0
Accuracy: 0.631578947368421

